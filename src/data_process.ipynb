{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import SimpleITK as sitk \n",
    "import pandas as pds \n",
    "import numpy as np \n",
    "from math import ceil \n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from tools import resample_multiprocesses\n",
    "\n",
    "import sklearn.metrics as skMetrics\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = pds.read_csv(os.path.join(\"..\", \"data\", \"stoic2021\", \"reference.csv\"))\n",
    "dataInfo = {}\n",
    "exclusivedFname = []\n",
    "\n",
    "for fname, isCovid, isSevere in zip(csvFile[\"PatientID\"], csvFile[\"probCOVID\"], csvFile[\"probSevere\"]):\n",
    "    if fname in exclusivedFname:\n",
    "        continue\n",
    "\n",
    "    dataInfo[fname] = [isCovid, isSevere]\n",
    "\n",
    "with open(os.path.join(\"..\", \"data\", \"stoic2021\", \"LabelInfo.pth\"), \"wb\") as f:\n",
    "    pickle.dump(dataInfo, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pretrain Wrap\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model.resnet import ResNet, BasicBlock\n",
    "\n",
    "networkTag = \"resnet_10\"\n",
    "\n",
    "resnet = nn.DataParallel(ResNet(BasicBlock, [1, 1, 1, 1], 0, 0, 0, 2))\n",
    "netPrams = resnet.state_dict()\n",
    "params = torch.load(os.path.join(\"weights\", \"{}.pth\".format(networkTag)), map_location=\"cpu\")\n",
    "\n",
    "params = {k: v for k, v in params['state_dict'].items() if k in resnet.state_dict().keys()}\n",
    "netPrams.update(params)\n",
    "\n",
    "resnet.load_state_dict(netPrams)\n",
    "\n",
    "results = {\n",
    "    \"params\": resnet.module.state_dict(),\n",
    "}\n",
    "\n",
    "torch.save(results, os.path.join(\"..\", \"record\", \"pretrain\", \"{}.pth\".format(networkTag)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Arrange Model\n",
    "# '''\n",
    "\n",
    "# fold_num = 5\n",
    "# dataset_name = 'TAPVC'\n",
    "# data_spacing = '1_1_1'\n",
    "# model_tag = '{}_coarse_{}'.format(dataset_name, \"tversky_0.3_0.7\")\n",
    "\n",
    "# model_path = os.path.join('..', 'record', '{}_coarse_tversky'.format(dataset_name))\n",
    "\n",
    "# for i in range(fold_num):\n",
    "#     curr_path = os.path.join('..', 'record', '{}_coarse_fold{}.pth'.format(dataset_name, i))\n",
    "#     if os.path.exists(curr_path) == False:\n",
    "#         os.mkdir(curr_path)\n",
    "#         os.mkdir(os.path.join(curr_path, 'data'))\n",
    "#         os.mkdir(os.path.join(curr_path, 'model'))\n",
    "\n",
    "#     os.link(os.path.join(model_path, '{}_fold{}.pth'.format(model_tag, i), 'model', 'best_model.pth'), os.path.join(curr_path, 'model', 'best_model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "all data \n",
    "PA:1\n",
    "'''\n",
    "\n",
    "# data_path = os.path.join('..', 'data', 'Resampled')\n",
    "# target_path = os.path.join('..', 'data', 'all_data')\n",
    "\n",
    "# data_path = os.path.abspath(data_path)\n",
    "# target_path = os.path.abspath(target_path)\n",
    "\n",
    "# if os.path.exists(target_path) == False:\n",
    "#     os.mkdir(target_path)\n",
    "\n",
    "# for s in os.listdir(data_path):\n",
    "#     if os.path.exists(os.path.join(target_path, s)) == False:\n",
    "#         os.mkdir(os.path.join(target_path, s))\n",
    "\n",
    "#     PV = sitk.ReadImage(os.path.join(data_path, s, 'PV.nii.gz'))\n",
    "#     LA = sitk.ReadImage(os.path.join(data_path, s, 'LA.nii.gz'))\n",
    "\n",
    "#     spacing = PV.GetSpacing()\n",
    "#     PV = sitk.GetArrayFromImage(PV)\n",
    "#     LA = sitk.GetArrayFromImage(LA)\n",
    "\n",
    "#     label = np.zeros_like(PV)\n",
    "#     label[PV.astype('bool')] = 1\n",
    "#     label[LA.astype('bool')] = 2\n",
    "\n",
    "#     label = label.astype('uint8')\n",
    "#     label = sitk.GetImageFromArray(label)\n",
    "#     label.SetSpacing(spacing)\n",
    "\n",
    "#     sitk.WriteImage(label, os.path.join(target_path, s, 'mask.nii.gz'))\n",
    "#     os.symlink(os.path.join(data_path, s, 'image.nii.gz'), os.path.join(target_path, s, 'im.nii.gz'))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# '''\n",
    "# data information\n",
    "# '''\n",
    "\n",
    "data_path = os.path.join('..', 'data', 'stoic2021', 'data_2')\n",
    "\n",
    "data = {\n",
    "    'fname':[],\n",
    "    'size_x':[],\n",
    "    'size_y':[],\n",
    "    'size_z':[],\n",
    "    'spacing_x':[],\n",
    "    'spacing_y':[],\n",
    "    'spacing_z':[],\n",
    "    'I_max':[],\n",
    "    'I_min':[],\n",
    "    'I_mid':[],\n",
    "    'I_mean':[],\n",
    "    'I_var':[]\n",
    "}\n",
    "\n",
    "for fname in tqdm(os.listdir(data_path)):\n",
    "    image = sitk.ReadImage(os.path.join(data_path, fname))\n",
    "\n",
    "    size_x, size_y, size_z = image.GetSize()\n",
    "    spacing_x, spacing_y, spacing_z = image.GetSpacing()\n",
    "\n",
    "    image = sitk.GetArrayFromImage(image)\n",
    "\n",
    "    data['fname'].append(fname)\n",
    "    data['size_x'].append(size_x)\n",
    "    data['size_y'].append(size_y)\n",
    "    data['size_z'].append(size_z)\n",
    "    data['spacing_x'].append(spacing_x)\n",
    "    data['spacing_y'].append(spacing_y)\n",
    "    data['spacing_z'].append(spacing_z)\n",
    "    data['I_max'].append(image.max())\n",
    "    data['I_min'].append(image.min())\n",
    "    data['I_mid'].append(np.median(image))\n",
    "    data['I_mean'].append(image.mean())\n",
    "    data['I_var'].append(image.var())\n",
    "\n",
    "data = pds.DataFrame(data)\n",
    "data.to_csv('data_inform.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_fname = []\n",
    "\n",
    "# for fname in os.listdir('../data/7.4newdata'):\n",
    "#     test_fname.append(fname)\n",
    "\n",
    "# with open(os.path.join('../data/splits', 'test.pth'), 'wb') as f:\n",
    "#     pickle.dump(test_fname, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Data preprocess\n",
    "'''\n",
    "\n",
    "data_path = os.path.join('..', 'data', 'stoic2021', 'data')\n",
    "target_path = os.path.join('..', 'data', 'stoic2021', 'data_3')\n",
    "\n",
    "if os.path.exists(target_path) == False:\n",
    "    os.mkdir(target_path)\n",
    "\n",
    "path_list = []\n",
    "for fname in os.listdir(data_path):\n",
    "    path_list.append(os.path.join(data_path, fname))\n",
    "\n",
    "resample_multiprocesses.Resample(path_list, target_path, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "data split\n",
    "'''\n",
    "\n",
    "fold_num = 5\n",
    "\n",
    "tapvcInfo = {}\n",
    "with open(os.path.join(\"..\", \"data\", \"stoic2021\", \"LabelInfo.pth\"), \"rb\") as f:\n",
    "    tapvcInfo = pickle.load(f)\n",
    "\n",
    "fname_list = list(tapvcInfo.keys())\n",
    "label00List = []\n",
    "label10List = []\n",
    "label11List = []\n",
    "\n",
    "for patientName in fname_list:\n",
    "    if 0 == tapvcInfo[patientName][0] and 0 == tapvcInfo[patientName][1]:\n",
    "        label00List.append(patientName)\n",
    "    elif 1 == tapvcInfo[patientName][0] and 0 == tapvcInfo[patientName][1]:\n",
    "        label10List.append(patientName)\n",
    "    elif 1 == tapvcInfo[patientName][0] and 1 == tapvcInfo[patientName][1]:\n",
    "        label11List.append(patientName)\n",
    "    else:\n",
    "        print(\"Invalid item: {}\".format(patientName))\n",
    "\n",
    "print(len(label00List), len(label10List), len(label11List))\n",
    "\n",
    "target_path = os.path.join('..', 'data', 'stoic2021', 'splits_cls')\n",
    "# fname_list = sorted(fname_list, key = lambda x: x)\n",
    "\n",
    "if os.path.exists(target_path) == False:\n",
    "    os.mkdir(target_path)\n",
    "\n",
    "fold_num00_list = []\n",
    "fold_num10_list = []\n",
    "fold_num11_list = []\n",
    "for i in range(fold_num):\n",
    "    if i == fold_num - 1:\n",
    "        fold_num00_list.append(len(label00List) - sum(fold_num00_list))\n",
    "        fold_num10_list.append(len(label10List) - sum(fold_num10_list))\n",
    "        fold_num11_list.append(len(label11List) - sum(fold_num11_list))\n",
    "    else:\n",
    "        fold_num00_list.append(ceil(len(label00List) / fold_num))\n",
    "        fold_num10_list.append(ceil(len(label10List) / fold_num))\n",
    "        fold_num11_list.append(ceil(len(label11List) / fold_num))\n",
    "\n",
    "label00List = np.array(label00List)\n",
    "label10List = np.array(label10List)\n",
    "label11List = np.array(label11List)\n",
    "index0 = list(range(len(label00List)))\n",
    "index1 = list(range(len(label10List)))\n",
    "index2 = list(range(len(label11List)))\n",
    "np.random.shuffle(index1)\n",
    "np.random.shuffle(index0)\n",
    "np.random.shuffle(index2)\n",
    "\n",
    "for i in range(len(fold_num00_list)):\n",
    "    num0 = fold_num00_list[i]\n",
    "    num1 = fold_num10_list[i]\n",
    "    num2 = fold_num11_list[i]\n",
    "\n",
    "    start0 = sum(fold_num00_list[0:i])\n",
    "    end0 = start0 + num0\n",
    "\n",
    "    start1 = sum(fold_num10_list[0:i])\n",
    "    end1 = start1 + num1\n",
    "\n",
    "    start2 = sum(fold_num11_list[0:i])\n",
    "    end2 = start2 + num2\n",
    "\n",
    "    f_list = list(label00List[start0:end0]) + list(label10List[start1:end1]) + list(label11List[start2:end2])\n",
    "\n",
    "    with open(os.path.join(target_path, 'fold{}.pth'.format(i)), 'wb') as f:\n",
    "        pickle.dump(f_list, f)\n",
    "\n",
    "for fname in os.listdir(os.path.join(target_path)):\n",
    "    with open(os.path.join(target_path, fname), 'rb') as f:\n",
    "        f_list = pickle.load(f)\n",
    "\n",
    "    print(fname, len(f_list))\n",
    "    print(f_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "coarse_label arrange\n",
    "'''\n",
    "\n",
    "coarse_model_tag = 'TAPVC_coarse_fold{}.pth'\n",
    "num_model = 5\n",
    "target_path = os.path.join('..', 'data', 'TAPVC_coarse')\n",
    "if os.path.exists(target_path) == False:\n",
    "    os.mkdir(target_path)\n",
    "\n",
    "data_list = []\n",
    "for i in range(num_model):\n",
    "    source_path = os.path.join('..', 'record', coarse_model_tag.format(i), 'data')\n",
    "    source_path = os.path.abspath(source_path)\n",
    "\n",
    "    for fname in os.listdir(source_path):\n",
    "        if fname.endswith('csv'):\n",
    "            data_list.append(pds.read_csv(os.path.join(source_path, fname)))\n",
    "            os.link(os.path.join(source_path, fname), os.path.join(target_path, \"summary_{}.csv\".format(i)))\n",
    "            continue\n",
    "        \n",
    "        if os.path.exists(os.path.join(target_path, fname)) == False:\n",
    "            os.mkdir(os.path.join(target_path, fname))\n",
    "        os.link(os.path.join(source_path, fname, 'predict.nii.gz'), os.path.join(target_path, fname, 'predict.nii.gz'))\n",
    "        os.link(os.path.join(source_path, fname, 'im.nii.gz'), os.path.join(target_path, fname, 'im.nii.gz'))\n",
    "        try:\n",
    "            os.link(os.path.join(source_path, fname, 'mask.nii.gz'), os.path.join(target_path, fname, 'mask.nii.gz'))\n",
    "            os.link(os.path.join(source_path, fname, 'probmap.nii.gz'), os.path.join(target_path, fname, 'probmap.nii.gz'))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "data_list = pds.concat(data_list)\n",
    "data_list.to_csv(os.path.join(target_path, 'summary.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "ROI statics\n",
    "'''\n",
    "\n",
    "predict_path = os.path.join('..', 'data', 'TAPVC_fine', \"TAPVC_fine_duc_ds_gatt_2_4_best\")\n",
    "data_path = os.path.join('..', 'data', 'TAPVC', 'all_data_0.35_0.35_0.625')\n",
    "expand_num = (0,0,0)\n",
    "\n",
    "def getROI(label):\n",
    "    def findMargin(sum_list):\n",
    "        for i, v in enumerate(sum_list):\n",
    "            lower = i\n",
    "            if v != 0:\n",
    "                break\n",
    "\n",
    "        sum_list.reverse()\n",
    "        for i, v in enumerate(sum_list):\n",
    "            upper = len(sum_list) - i\n",
    "            if v != 0:\n",
    "                break\n",
    "                \n",
    "        if upper < lower:\n",
    "            return upper, lower\n",
    "        else:\n",
    "            return lower, upper\n",
    "\n",
    "    margin_list = []\n",
    "    for i in range(label.ndim):\n",
    "        edge_view = np.swapaxes(label, 0, i)\n",
    "        l = edge_view.shape[0]\n",
    "        edge_view = edge_view.reshape((l, -1)).sum(axis=1)\n",
    "        lower, upper = findMargin(list(edge_view))\n",
    "\n",
    "        margin_list.append((lower, upper))\n",
    "\n",
    "    return margin_list\n",
    "\n",
    "data = {\n",
    "    'id':[],\n",
    "    'z':[],\n",
    "    'y':[],\n",
    "    'x':[],\n",
    "    'rate':[],\n",
    "}\n",
    "\n",
    "for fid in tqdm(os.listdir(predict_path)):\n",
    "    if fid.endswith('csv') == True:\n",
    "        continue\n",
    "\n",
    "    prediction = sitk.ReadImage(os.path.join(predict_path, fid, 'predict.nii.gz'))\n",
    "    label = sitk.ReadImage(os.path.join(data_path, fid, 'mask.nii.gz'))\n",
    "\n",
    "    prediction = sitk.GetArrayFromImage(prediction)\n",
    "    label = sitk.GetArrayFromImage(label)\n",
    "\n",
    "    prediction = prediction.astype('bool').astype('int')\n",
    "    label = label.astype('bool').astype('int')\n",
    "\n",
    "    if prediction.shape != label.shape:\n",
    "        print(fid)\n",
    "\n",
    "    margin_list = getROI(prediction)\n",
    "   \n",
    "    new_margin_list = []\n",
    "    for i, margin in enumerate(margin_list):\n",
    "        lower, upper = margin\n",
    "\n",
    "        lower = max(0, lower - expand_num[i])\n",
    "        upper = min(prediction.shape[i], upper + expand_num[i])\n",
    "\n",
    "        new_margin_list.append((lower, upper))\n",
    "\n",
    "    cropped_prediction = label[\n",
    "        new_margin_list[0][0]: new_margin_list[0][1],\n",
    "        new_margin_list[1][0]: new_margin_list[1][1],\n",
    "        new_margin_list[2][0]: new_margin_list[2][1],\n",
    "    ]\n",
    "\n",
    "    rate = cropped_prediction.sum() / label.sum()\n",
    "\n",
    "    data['id'].append(fid)\n",
    "    data['z'].append(cropped_prediction.shape[0])\n",
    "    data['y'].append(cropped_prediction.shape[1])\n",
    "    data['x'].append(cropped_prediction.shape[2])\n",
    "    data['rate'].append(rate)\n",
    "\n",
    "data = pds.DataFrame(data)\n",
    "data.to_csv('ROI_inform.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Fine label arrange\n",
    "'''\n",
    "coarse_model_tag = 'stoic2021_resnet18_newpreprocess_v2_fold{}.pth'\n",
    "num_model = 5\n",
    "target_path = os.path.join('..', 'data', 'stoic2021_resnet18_newpreprocess_v2')\n",
    "if os.path.exists(target_path) == False:\n",
    "    os.mkdir(target_path)\n",
    "\n",
    "data_list = []\n",
    "for i in range(num_model):\n",
    "    source_path = os.path.join('..', 'record', coarse_model_tag.format(i), 'data')\n",
    "    source_path = os.path.abspath(source_path)\n",
    "\n",
    "    for j, fname in enumerate(os.listdir(source_path)):\n",
    "        if fname.endswith('csv'):\n",
    "            data_list.append(pds.read_csv(os.path.join(source_path, fname)))\n",
    "            os.link(os.path.join(source_path, fname), os.path.join(target_path, \"summary_{}.csv\".format(i)))\n",
    "            continue\n",
    "        \n",
    "        if os.path.exists(os.path.join(target_path, fname)) == False:\n",
    "            os.mkdir(os.path.join(target_path, fname))\n",
    "        \n",
    "        for subfname in os.listdir(os.path.join(source_path, fname)):\n",
    "            os.link(os.path.join(source_path, fname, subfname),\n",
    "            os.path.join(target_path, fname, subfname))\n",
    "\n",
    "data_list = pds.concat(data_list)\n",
    "data_list.to_csv(os.path.join(target_path, 'summary.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Result Report\n",
    "\n",
    "resultTag = \"stoic2021_resnet18_newpreprocess_v2\"\n",
    "threshold = 0.5\n",
    "\n",
    "referenceResult = {}\n",
    "logAns = []\n",
    "with open(os.path.join(\"..\", \"data\", \"stoic2021\", \"LabelInfo.pth\"), \"rb\") as f:\n",
    "    referenceResult = pickle.load(f)\n",
    "\n",
    "resultPath = os.path.join(\"..\", \"data\", resultTag)\n",
    "referenceList0 = []\n",
    "referenceList1 = []\n",
    "resultList0 = []\n",
    "resultList1 = []\n",
    "for patientName in os.listdir(resultPath):\n",
    "    if patientName.endswith(\".csv\"):\n",
    "        continue\n",
    "    patientName = int(patientName)\n",
    "    referenceList0.append(referenceResult[patientName][0])\n",
    "    referenceList1.append(referenceResult[patientName][1])\n",
    "    with open(os.path.join(resultPath, str(patientName), \"prob.pth\"), \"rb\") as f:\n",
    "        prob = pickle.load(f)\n",
    "        prob0 = prob[0].item()\n",
    "        prob1 = prob[1].item()\n",
    "        resultList0.append(prob0)\n",
    "        resultList1.append(prob1)\n",
    "fpr0, tpr0, _ = skMetrics.roc_curve(referenceList0, resultList0, drop_intermediate=False)\n",
    "fpr1, tpr1, _ = skMetrics.roc_curve(referenceList1, resultList1, drop_intermediate=False)\n",
    "auc0 = skMetrics.auc(fpr0, tpr0)\n",
    "auc1 = skMetrics.auc(fpr1, tpr1)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(fpr0, tpr0)\n",
    "plt.plot([0,1], [0,1], linestyle='--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.05])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(fpr1, tpr1)\n",
    "plt.plot([0,1], [0,1], linestyle='--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.05])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "binaryResultList0 = [i > threshold for i in resultList0]\n",
    "binaryResultList1 = [i > threshold for i in resultList1]\n",
    "\n",
    "accuracy = skMetrics.accuracy_score(referenceList0, binaryResultList0)\n",
    "f1 = skMetrics.f1_score(referenceList0, binaryResultList0)\n",
    "precision = skMetrics.precision_score(referenceList0, binaryResultList0)\n",
    "recall = skMetrics.recall_score(referenceList0, binaryResultList0)\n",
    "print(\"COVID:\\nAcc:{}\\nAUC:{}\\nF1:{}\\nPrecision:{}\\nRecall:{}\\n\".format(\n",
    "    accuracy, auc0, f1, precision, recall\n",
    "))\n",
    "\n",
    "accuracy = skMetrics.accuracy_score(referenceList1, binaryResultList1)\n",
    "f1 = skMetrics.f1_score(referenceList1, binaryResultList1)\n",
    "precision = skMetrics.precision_score(referenceList1, binaryResultList1)\n",
    "recall = skMetrics.recall_score(referenceList1, binaryResultList1)\n",
    "print(\"Severe:\\nAcc:{}\\nAUC:{}\\nF1:{}\\nPrecision:{}\\nRecall:{}\\n\".format(\n",
    "    accuracy, auc1, f1, precision, recall\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all Result Report\n",
    "\n",
    "def kROC(reference, prob, k = 0.01):\n",
    "    reference = np.array(reference)\n",
    "    prob = np.array(prob)\n",
    "\n",
    "    fprList = []\n",
    "    tprList = []\n",
    "    for threshold in np.arange(0, 1.00001, k):\n",
    "        fakePredict = prob > threshold\n",
    "        tprList.append((fakePredict * reference).sum() / reference.sum())\n",
    "        fprList.append(((1 - reference) * fakePredict).sum() / (1 - reference).sum())\n",
    "\n",
    "    return fprList, tprList       \n",
    "\n",
    "resultTagList = [\n",
    "    \"TAPVC_classify_softmax_resin_cam0.1_v3_None\",\n",
    "    # \"TAPVC_classify_softmax_resin_cam0.1_v3_loss1\",\n",
    "    # \"TAPVC_classify_softmax_resin_cam0.1_v3_loss2\",\n",
    "    \"TAPVC_classify_softmax_resin_cam0.1_v3\"]\n",
    "resultLabelList = [\n",
    "    \"Baseline\",\n",
    "    # \"Loss1\",\n",
    "    # \"Loss2\",\n",
    "    \"Loss1+Loss2\",\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(6.4,6.4))\n",
    "for resultTag, resultLabel in zip(resultTagList, resultLabelList):\n",
    "    referenceResult = {}\n",
    "    logAns = []\n",
    "    with open(os.path.join(\"..\", \"data\", \"tapvc_info.pth\"), \"rb\") as f:\n",
    "        referenceResult = pickle.load(f)\n",
    "\n",
    "    resultPath = os.path.join(\"..\", \"data\", resultTag)\n",
    "    referenceList = []\n",
    "    resultList = []\n",
    "    for patientName in os.listdir(resultPath):\n",
    "        if patientName.endswith(\".csv\"):\n",
    "            continue\n",
    "        referenceList.append(referenceResult[patientName][\"label2\"])\n",
    "        with open(os.path.join(resultPath, patientName, \"prob.pth\"), \"rb\") as f:\n",
    "            prob = pickle.load(f)\n",
    "            prob = prob[1].item()\n",
    "            resultList.append(prob)\n",
    "        logAns.append(\"{} {} {}\".format(patientName, referenceList[-1], resultList[-1]))\n",
    "    fpr, tpr, _ = skMetrics.roc_curve(referenceList, resultList, drop_intermediate=False)\n",
    "    # fpr, tpr = kROC(referenceList, resultList, k = 0.00001)\n",
    "    plt.plot(fpr, tpr, label=resultLabel)\n",
    "\n",
    "plt.legend()\n",
    "plt.plot([0,1], [0,1], linestyle='--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.xlabel(\"TPR\")\n",
    "plt.ylabel(\"FPR\")\n",
    "plt.ylim([0.0,1.05])\n",
    "plt.title(\"ROC Curves of Baseline Method and Proposed Method\")\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
