{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import SimpleITK as sitk \n",
    "import pandas as pds \n",
    "import numpy as np \n",
    "from math import ceil \n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from tools import resample_multiprocesses\n",
    "\n",
    "import sklearn.metrics as skMetrics\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = pds.read_csv(os.path.join(\"..\", \"data\", \"tapvc_info.csv\"))\n",
    "tapvcInfo = {}\n",
    "patientNameList = []\n",
    "for fname in os.listdir(os.path.join(\"..\", \"data\", \"TAPVC\", \"splits\")):\n",
    "    with open(os.path.join(\"..\", \"data\", \"TAPVC\", \"splits\", fname), \"rb\") as f:\n",
    "        patientNameList += pickle.load(f)\n",
    "nameInCSV = list(csvFile[\"name\"])\n",
    "\n",
    "count = 0\n",
    "for name in patientNameList:\n",
    "    try:\n",
    "        index = nameInCSV.index(name)\n",
    "        rowItem = csvFile.iloc[index]\n",
    "        storeItem = {\n",
    "            \"name\": rowItem[-1],\n",
    "            \"label1\": rowItem[-3],\n",
    "            \"label2\": rowItem[-2],\n",
    "            \"feature\": list(rowItem[1:-4])\n",
    "        }\n",
    "        tapvcInfo[name] = storeItem\n",
    "        count = count + 1\n",
    "    except:\n",
    "        print(\"No \", name)\n",
    "\n",
    "print(tapvcInfo)\n",
    "print(\"There are {} items.\".format(count))\n",
    "\n",
    "with open(os.path.join(\"..\", \"data\", \"tapvc_info.pth\"), \"wb\") as f:\n",
    "    pickle.dump(tapvcInfo, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Arrange Model\n",
    "'''\n",
    "\n",
    "fold_num = 5\n",
    "dataset_name = 'TAPVC'\n",
    "data_spacing = '1_1_1'\n",
    "model_tag = '{}_coarse_{}'.format(dataset_name, \"tversky_0.3_0.7\")\n",
    "\n",
    "model_path = os.path.join('..', 'record', '{}_coarse_tversky'.format(dataset_name))\n",
    "\n",
    "for i in range(fold_num):\n",
    "    curr_path = os.path.join('..', 'record', '{}_coarse_fold{}.pth'.format(dataset_name, i))\n",
    "    if os.path.exists(curr_path) == False:\n",
    "        os.mkdir(curr_path)\n",
    "        os.mkdir(os.path.join(curr_path, 'data'))\n",
    "        os.mkdir(os.path.join(curr_path, 'model'))\n",
    "\n",
    "    os.link(os.path.join(model_path, '{}_fold{}.pth'.format(model_tag, i), 'model', 'best_model.pth'), os.path.join(curr_path, 'model', 'best_model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "all data \n",
    "PA:1\n",
    "'''\n",
    "\n",
    "# data_path = os.path.join('..', 'data', 'Resampled')\n",
    "# target_path = os.path.join('..', 'data', 'all_data')\n",
    "\n",
    "# data_path = os.path.abspath(data_path)\n",
    "# target_path = os.path.abspath(target_path)\n",
    "\n",
    "# if os.path.exists(target_path) == False:\n",
    "#     os.mkdir(target_path)\n",
    "\n",
    "# for s in os.listdir(data_path):\n",
    "#     if os.path.exists(os.path.join(target_path, s)) == False:\n",
    "#         os.mkdir(os.path.join(target_path, s))\n",
    "\n",
    "#     PV = sitk.ReadImage(os.path.join(data_path, s, 'PV.nii.gz'))\n",
    "#     LA = sitk.ReadImage(os.path.join(data_path, s, 'LA.nii.gz'))\n",
    "\n",
    "#     spacing = PV.GetSpacing()\n",
    "#     PV = sitk.GetArrayFromImage(PV)\n",
    "#     LA = sitk.GetArrayFromImage(LA)\n",
    "\n",
    "#     label = np.zeros_like(PV)\n",
    "#     label[PV.astype('bool')] = 1\n",
    "#     label[LA.astype('bool')] = 2\n",
    "\n",
    "#     label = label.astype('uint8')\n",
    "#     label = sitk.GetImageFromArray(label)\n",
    "#     label.SetSpacing(spacing)\n",
    "\n",
    "#     sitk.WriteImage(label, os.path.join(target_path, s, 'mask.nii.gz'))\n",
    "#     os.symlink(os.path.join(data_path, s, 'image.nii.gz'), os.path.join(target_path, s, 'im.nii.gz'))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# '''\n",
    "# data information\n",
    "# '''\n",
    "\n",
    "data_path = os.path.join('..', 'data', 'TAPVC', 'all_data_0.35_0.35_0.625')\n",
    "\n",
    "data = {\n",
    "    'fname':[],\n",
    "    'size_x':[],\n",
    "    'size_y':[],\n",
    "    'size_z':[],\n",
    "    'spacing_x':[],\n",
    "    'spacing_y':[],\n",
    "    'spacing_z':[],\n",
    "    'I_max':[],\n",
    "    'I_min':[],\n",
    "    'I_mid':[],\n",
    "    'I_mean':[],\n",
    "    'I_var':[]\n",
    "}\n",
    "\n",
    "for fname in tqdm(os.listdir(data_path)):\n",
    "    image = sitk.ReadImage(os.path.join(data_path, fname, 'im.nii.gz'))\n",
    "    label = sitk.ReadImage(os.path.join(data_path, fname, 'mask.nii.gz'))\n",
    "\n",
    "    if image.GetSize() != label.GetSize():\n",
    "        print(fname)\n",
    "\n",
    "    size_x, size_y, size_z = image.GetSize()\n",
    "    spacing_x, spacing_y, spacing_z = image.GetSpacing()\n",
    "\n",
    "    image = sitk.GetArrayFromImage(image)\n",
    "    label = sitk.GetArrayFromImage(label)\n",
    "\n",
    "    label = label.astype('bool')\n",
    "    label_pixels = image[label]\n",
    "    label_pixels = np.sort(label_pixels)\n",
    "    l = int(len(label_pixels) * 0.05)\n",
    "    label_pixels = label_pixels[l:(len(label_pixels) - l)]\n",
    "\n",
    "    data['fname'].append(fname)\n",
    "    data['size_x'].append(size_x)\n",
    "    data['size_y'].append(size_y)\n",
    "    data['size_z'].append(size_z)\n",
    "    data['spacing_x'].append(spacing_x)\n",
    "    data['spacing_y'].append(spacing_y)\n",
    "    data['spacing_z'].append(spacing_z)\n",
    "    data['I_max'].append(label_pixels.max())\n",
    "    data['I_min'].append(label_pixels.min())\n",
    "    data['I_mid'].append(np.median(label_pixels))\n",
    "    data['I_mean'].append(label_pixels.mean())\n",
    "    data['I_var'].append(label_pixels.var())\n",
    "\n",
    "data = pds.DataFrame(data)\n",
    "data.to_csv('data_inform.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_fname = []\n",
    "\n",
    "# for fname in os.listdir('../data/7.4newdata'):\n",
    "#     test_fname.append(fname)\n",
    "\n",
    "# with open(os.path.join('../data/splits', 'test.pth'), 'wb') as f:\n",
    "#     pickle.dump(test_fname, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# '''\n",
    "# Image Resample\n",
    "# '''\n",
    "\n",
    "# data_path = os.path.join('..', 'data', 'TAPVC', 'all_data')\n",
    "# target_path = os.path.join('..', 'data', 'TAPVC', 'all_data_0.35_0.35_0.625')\n",
    "\n",
    "# if os.path.exists(target_path) == False:\n",
    "#     os.mkdir(target_path)\n",
    "\n",
    "# path_list = []\n",
    "# for fname in os.listdir(data_path):\n",
    "#     path_list.append(os.path.join(data_path, fname))\n",
    "\n",
    "# resample_multiprocesses.Resample(path_list, target_path, (0.35,0.35,0.625), 8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# '''\n",
    "# data split\n",
    "# '''\n",
    "\n",
    "# fold_num = 5\n",
    "\n",
    "# tapvcInfo = {}\n",
    "# with open(os.path.join(\"..\", \"data\", \"tapvc_info.pth\"), \"rb\") as f:\n",
    "#     tapvcInfo = pickle.load(f)\n",
    "\n",
    "# fname_list = list(tapvcInfo.keys())\n",
    "# label1List = []\n",
    "# label0List = []\n",
    "\n",
    "# for patientName in fname_list:\n",
    "#     if 0 == tapvcInfo[patientName][\"label2\"]:\n",
    "#         label0List.append(patientName)\n",
    "#     else:\n",
    "#         label1List.append(patientName)\n",
    "\n",
    "# print(len(label0List), len(label1List))\n",
    "\n",
    "# target_path = os.path.join('..', 'data', 'TAPVC', 'splits_cls')\n",
    "# # fname_list = sorted(fname_list, key = lambda x: x)\n",
    "\n",
    "# if os.path.exists(target_path) == False:\n",
    "#     os.mkdir(target_path)\n",
    "\n",
    "# fold_num0_list = []\n",
    "# fold_num1_list = []\n",
    "# for i in range(fold_num):\n",
    "#     if i == fold_num - 1:\n",
    "#         fold_num0_list.append(len(label0List) - sum(fold_num0_list))\n",
    "#         fold_num1_list.append(len(label1List) - sum(fold_num1_list))\n",
    "#     else:\n",
    "#         fold_num0_list.append(ceil(len(label0List) / fold_num))\n",
    "#         fold_num1_list.append(ceil(len(label1List) / fold_num))\n",
    "\n",
    "\n",
    "\n",
    "# label0List = np.array(label0List)\n",
    "# label1List = np.array(label1List)\n",
    "# index0 = list(range(len(label0List)))\n",
    "# index1 = list(range(len(label1List)))\n",
    "# np.random.shuffle(index1)\n",
    "# np.random.shuffle(index0)\n",
    "\n",
    "# for i in range(len(fold_num0_list)):\n",
    "#     num0 = fold_num0_list[i]\n",
    "#     num1 = fold_num1_list[i]\n",
    "\n",
    "#     start0 = sum(fold_num0_list[0:i])\n",
    "#     end0 = start0 + num0\n",
    "\n",
    "#     start1 = sum(fold_num1_list[0:i])\n",
    "#     end1 = start1 + num1\n",
    "\n",
    "\n",
    "#     f_list = list(label0List[start0:end0]) + list(label1List[start1:end1])\n",
    "\n",
    "#     with open(os.path.join(target_path, 'fold{}.pth'.format(i)), 'wb') as f:\n",
    "#         pickle.dump(f_list, f)\n",
    "\n",
    "# for fname in os.listdir(os.path.join(target_path)):\n",
    "#     with open(os.path.join(target_path, fname), 'rb') as f:\n",
    "#         f_list = pickle.load(f)\n",
    "\n",
    "#     print(fname, len(f_list))\n",
    "#     print(f_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "coarse_label arrange\n",
    "'''\n",
    "\n",
    "coarse_model_tag = 'TAPVC_coarse_fold{}.pth'\n",
    "num_model = 5\n",
    "target_path = os.path.join('..', 'data', 'TAPVC_coarse')\n",
    "if os.path.exists(target_path) == False:\n",
    "    os.mkdir(target_path)\n",
    "\n",
    "data_list = []\n",
    "for i in range(num_model):\n",
    "    source_path = os.path.join('..', 'record', coarse_model_tag.format(i), 'data')\n",
    "    source_path = os.path.abspath(source_path)\n",
    "\n",
    "    for fname in os.listdir(source_path):\n",
    "        if fname.endswith('csv'):\n",
    "            data_list.append(pds.read_csv(os.path.join(source_path, fname)))\n",
    "            os.link(os.path.join(source_path, fname), os.path.join(target_path, \"summary_{}.csv\".format(i)))\n",
    "            continue\n",
    "        \n",
    "        if os.path.exists(os.path.join(target_path, fname)) == False:\n",
    "            os.mkdir(os.path.join(target_path, fname))\n",
    "        os.link(os.path.join(source_path, fname, 'predict.nii.gz'), os.path.join(target_path, fname, 'predict.nii.gz'))\n",
    "        os.link(os.path.join(source_path, fname, 'im.nii.gz'), os.path.join(target_path, fname, 'im.nii.gz'))\n",
    "        try:\n",
    "            os.link(os.path.join(source_path, fname, 'mask.nii.gz'), os.path.join(target_path, fname, 'mask.nii.gz'))\n",
    "            os.link(os.path.join(source_path, fname, 'probmap.nii.gz'), os.path.join(target_path, fname, 'probmap.nii.gz'))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "data_list = pds.concat(data_list)\n",
    "data_list.to_csv(os.path.join(target_path, 'summary.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "ROI statics\n",
    "'''\n",
    "\n",
    "predict_path = os.path.join('..', 'data', 'TAPVC_fine', \"TAPVC_fine_duc_ds_gatt_2_4_best\")\n",
    "data_path = os.path.join('..', 'data', 'TAPVC', 'all_data_0.35_0.35_0.625')\n",
    "expand_num = (0,0,0)\n",
    "\n",
    "def getROI(label):\n",
    "    def findMargin(sum_list):\n",
    "        for i, v in enumerate(sum_list):\n",
    "            lower = i\n",
    "            if v != 0:\n",
    "                break\n",
    "\n",
    "        sum_list.reverse()\n",
    "        for i, v in enumerate(sum_list):\n",
    "            upper = len(sum_list) - i\n",
    "            if v != 0:\n",
    "                break\n",
    "                \n",
    "        if upper < lower:\n",
    "            return upper, lower\n",
    "        else:\n",
    "            return lower, upper\n",
    "\n",
    "    margin_list = []\n",
    "    for i in range(label.ndim):\n",
    "        edge_view = np.swapaxes(label, 0, i)\n",
    "        l = edge_view.shape[0]\n",
    "        edge_view = edge_view.reshape((l, -1)).sum(axis=1)\n",
    "        lower, upper = findMargin(list(edge_view))\n",
    "\n",
    "        margin_list.append((lower, upper))\n",
    "\n",
    "    return margin_list\n",
    "\n",
    "data = {\n",
    "    'id':[],\n",
    "    'z':[],\n",
    "    'y':[],\n",
    "    'x':[],\n",
    "    'rate':[],\n",
    "}\n",
    "\n",
    "for fid in tqdm(os.listdir(predict_path)):\n",
    "    if fid.endswith('csv') == True:\n",
    "        continue\n",
    "\n",
    "    prediction = sitk.ReadImage(os.path.join(predict_path, fid, 'predict.nii.gz'))\n",
    "    label = sitk.ReadImage(os.path.join(data_path, fid, 'mask.nii.gz'))\n",
    "\n",
    "    prediction = sitk.GetArrayFromImage(prediction)\n",
    "    label = sitk.GetArrayFromImage(label)\n",
    "\n",
    "    prediction = prediction.astype('bool').astype('int')\n",
    "    label = label.astype('bool').astype('int')\n",
    "\n",
    "    if prediction.shape != label.shape:\n",
    "        print(fid)\n",
    "\n",
    "    margin_list = getROI(prediction)\n",
    "   \n",
    "    new_margin_list = []\n",
    "    for i, margin in enumerate(margin_list):\n",
    "        lower, upper = margin\n",
    "\n",
    "        lower = max(0, lower - expand_num[i])\n",
    "        upper = min(prediction.shape[i], upper + expand_num[i])\n",
    "\n",
    "        new_margin_list.append((lower, upper))\n",
    "\n",
    "    cropped_prediction = label[\n",
    "        new_margin_list[0][0]: new_margin_list[0][1],\n",
    "        new_margin_list[1][0]: new_margin_list[1][1],\n",
    "        new_margin_list[2][0]: new_margin_list[2][1],\n",
    "    ]\n",
    "\n",
    "    rate = cropped_prediction.sum() / label.sum()\n",
    "\n",
    "    data['id'].append(fid)\n",
    "    data['z'].append(cropped_prediction.shape[0])\n",
    "    data['y'].append(cropped_prediction.shape[1])\n",
    "    data['x'].append(cropped_prediction.shape[2])\n",
    "    data['rate'].append(rate)\n",
    "\n",
    "data = pds.DataFrame(data)\n",
    "data.to_csv('ROI_inform.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Fine label arrange\n",
    "'''\n",
    "coarse_model_tag = 'TAPVC_classify_softmax_resin_cam0.1_v3_fold{}.pth'\n",
    "num_model = 5\n",
    "target_path = os.path.join('..', 'data', 'TAPVC_classify_softmax_resin_cam0.1_v3')\n",
    "if os.path.exists(target_path) == False:\n",
    "    os.mkdir(target_path)\n",
    "\n",
    "data_list = []\n",
    "for i in range(num_model):\n",
    "    source_path = os.path.join('..', 'record', coarse_model_tag.format(i), 'data')\n",
    "    source_path = os.path.abspath(source_path)\n",
    "\n",
    "    for j, fname in enumerate(os.listdir(source_path)):\n",
    "        if fname.endswith('csv'):\n",
    "            data_list.append(pds.read_csv(os.path.join(source_path, fname)))\n",
    "            os.link(os.path.join(source_path, fname), os.path.join(target_path, \"summary_{}.csv\".format(i)))\n",
    "            continue\n",
    "        \n",
    "        if os.path.exists(os.path.join(target_path, fname)) == False:\n",
    "            os.mkdir(os.path.join(target_path, fname))\n",
    "        \n",
    "        for subfname in os.listdir(os.path.join(source_path, fname)):\n",
    "            os.link(os.path.join(source_path, fname, subfname),\n",
    "            os.path.join(target_path, fname, subfname))\n",
    "\n",
    "data_list = pds.concat(data_list)\n",
    "data_list.to_csv(os.path.join(target_path, 'summary.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Result Report\n",
    "\n",
    "resultTag = \"TAPVC_classify_softmax_resin_cam0.1_v3\"\n",
    "threshold = 0.5\n",
    "\n",
    "referenceResult = {}\n",
    "logAns = []\n",
    "with open(os.path.join(\"..\", \"data\", \"tapvc_info.pth\"), \"rb\") as f:\n",
    "    referenceResult = pickle.load(f)\n",
    "\n",
    "resultPath = os.path.join(\"..\", \"data\", resultTag)\n",
    "referenceList = []\n",
    "resultList = []\n",
    "for patientName in os.listdir(resultPath):\n",
    "    if patientName.endswith(\".csv\"):\n",
    "        continue\n",
    "    referenceList.append(referenceResult[patientName][\"label2\"])\n",
    "    with open(os.path.join(resultPath, patientName, \"prob.pth\"), \"rb\") as f:\n",
    "        prob = pickle.load(f)\n",
    "        print(\"{}_{}_{}_{}\".format(patientName, referenceResult[patientName][\"label2\"], prob[0], prob[1]))\n",
    "        prob = prob[1].item()\n",
    "        resultList.append(prob)\n",
    "    logAns.append(\"{} {} {}\".format(patientName, referenceList[-1], resultList[-1]))\n",
    "fpr, tpr, _ = skMetrics.roc_curve(referenceList, resultList, drop_intermediate=False)\n",
    "auc = skMetrics.auc(fpr, tpr)\n",
    "\n",
    "precision, recall, thresholds = skMetrics.precision_recall_curve(referenceList, resultList)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1], [0,1], linestyle='--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.05])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(recall, precision)\n",
    "plt.plot([0,1], [0,1], linestyle='--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.05])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "binaryResultList = [i > threshold for i in resultList]\n",
    "\n",
    "accuracy = skMetrics.accuracy_score(referenceList, binaryResultList)\n",
    "f1 = skMetrics.f1_score(referenceList, binaryResultList)\n",
    "precision = skMetrics.precision_score(referenceList, binaryResultList)\n",
    "recall = skMetrics.recall_score(referenceList, binaryResultList)\n",
    "print(\"Acc:{}\\nAUC:{}\\nF1:{}\\nPrecision:{}\\nRecall:{}\\n\".format(\n",
    "    accuracy, auc, f1, precision, recall\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all Result Report\n",
    "\n",
    "def kROC(reference, prob, k = 0.01):\n",
    "    reference = np.array(reference)\n",
    "    prob = np.array(prob)\n",
    "\n",
    "    fprList = []\n",
    "    tprList = []\n",
    "    for threshold in np.arange(0, 1.00001, k):\n",
    "        fakePredict = prob > threshold\n",
    "        tprList.append((fakePredict * reference).sum() / reference.sum())\n",
    "        fprList.append(((1 - reference) * fakePredict).sum() / (1 - reference).sum())\n",
    "\n",
    "    return fprList, tprList       \n",
    "\n",
    "resultTagList = [\n",
    "    \"TAPVC_classify_softmax_resin_cam0.1_v3_None\",\n",
    "    # \"TAPVC_classify_softmax_resin_cam0.1_v3_loss1\",\n",
    "    # \"TAPVC_classify_softmax_resin_cam0.1_v3_loss2\",\n",
    "    \"TAPVC_classify_softmax_resin_cam0.1_v3\"]\n",
    "resultLabelList = [\n",
    "    \"Baseline\",\n",
    "    # \"Loss1\",\n",
    "    # \"Loss2\",\n",
    "    \"Loss1+Loss2\",\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(6.4,6.4))\n",
    "for resultTag, resultLabel in zip(resultTagList, resultLabelList):\n",
    "    referenceResult = {}\n",
    "    logAns = []\n",
    "    with open(os.path.join(\"..\", \"data\", \"tapvc_info.pth\"), \"rb\") as f:\n",
    "        referenceResult = pickle.load(f)\n",
    "\n",
    "    resultPath = os.path.join(\"..\", \"data\", resultTag)\n",
    "    referenceList = []\n",
    "    resultList = []\n",
    "    for patientName in os.listdir(resultPath):\n",
    "        if patientName.endswith(\".csv\"):\n",
    "            continue\n",
    "        referenceList.append(referenceResult[patientName][\"label2\"])\n",
    "        with open(os.path.join(resultPath, patientName, \"prob.pth\"), \"rb\") as f:\n",
    "            prob = pickle.load(f)\n",
    "            prob = prob[1].item()\n",
    "            resultList.append(prob)\n",
    "        logAns.append(\"{} {} {}\".format(patientName, referenceList[-1], resultList[-1]))\n",
    "    fpr, tpr, _ = skMetrics.roc_curve(referenceList, resultList, drop_intermediate=False)\n",
    "    # fpr, tpr = kROC(referenceList, resultList, k = 0.00001)\n",
    "    plt.plot(fpr, tpr, label=resultLabel)\n",
    "\n",
    "plt.legend()\n",
    "plt.plot([0,1], [0,1], linestyle='--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.xlabel(\"TPR\")\n",
    "plt.ylabel(\"FPR\")\n",
    "plt.ylim([0.0,1.05])\n",
    "plt.title(\"ROC Curves of Baseline Method and Proposed Method\")\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
